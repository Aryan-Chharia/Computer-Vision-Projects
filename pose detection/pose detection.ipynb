{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11fe8b-67aa-4005-8f71-bed13ecd836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465d1fa-bbae-4b13-8f20-09075d974d29",
   "metadata": {},
   "source": [
    "## 1. Import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf0f525-66fe-40a9-b476-cf0c9eee302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf8a9c-8cc9-4c82-9f1a-2fb4c8b84a87",
   "metadata": {},
   "source": [
    "## 2. Initialize mediapipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a888f6e0-1ba0-4057-bdde-8f4d24e0d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # help in drawing on the input video/image\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433de3c-e5f0-448a-ad40-457ebfad40e4",
   "metadata": {},
   "source": [
    "## 3. Check:- Mediapipe is working properly or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f22c879-19d8-4645-a6cb-bd4f0b4736cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Documents\\llm\\cuda\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolour feed\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame.flags.writeable = False\n",
    "\n",
    "        # Make detections\n",
    "        results = pose.process(frame)\n",
    "\n",
    "        # Recolour back for rendering\n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(117,66,117), thickness=2, circle_radius=2))\n",
    "    \n",
    "        cv2.imshow('Initial Raw webcam feed',frame)\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6c6e8-1c84-4eb1-a996-10a11b0c8b5b",
   "metadata": {},
   "source": [
    "## 4. Capture Video for ML model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd84a0-517c-492d-879e-be9f7ce3e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "videoWriter = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc('P', 'I', 'M', '1'), fps, (int(width), int(height)))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    try:\n",
    "        cv2.imshow('Saving Video', frame)\n",
    "        videoWriter.write(frame)\n",
    "    except Exception as e:\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(\"Video saved\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5d8dd-4c22-4589-8e45-c8446c1ea56b",
   "metadata": {},
   "source": [
    "## 5. Capture landmarks from video and export to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8dfb2e-799d-4a03-b3a7-495075aef4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06992fb-2103-4b45-9241-6301713b4a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ae8ed-5c0f-4ebe-a11f-27b41b76f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('landmarks.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c180f2-4e37-4465-a483-1b40359e3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmarks(results, action):\n",
    "    try:\n",
    "        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "        keypoints.insert(0, action)\n",
    "\n",
    "        with open('landmarks.csv', mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "051617f0-7295-465a-bf3d-1e9c40a35f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "landmark {\n",
       "  x: 0.582444966\n",
       "  y: 0.566214144\n",
       "  z: -0.84398973\n",
       "  visibility: 0.999964833\n",
       "}\n",
       "landmark {\n",
       "  x: 0.603772283\n",
       "  y: 0.496982753\n",
       "  z: -0.794165671\n",
       "  visibility: 0.99993\n",
       "}\n",
       "landmark {\n",
       "  x: 0.621761\n",
       "  y: 0.495295525\n",
       "  z: -0.794160843\n",
       "  visibility: 0.999943733\n",
       "}\n",
       "landmark {\n",
       "  x: 0.638644457\n",
       "  y: 0.494484633\n",
       "  z: -0.794403195\n",
       "  visibility: 0.999923\n",
       "}\n",
       "landmark {\n",
       "  x: 0.546986818\n",
       "  y: 0.504129469\n",
       "  z: -0.79225111\n",
       "  visibility: 0.999930859\n",
       "}\n",
       "landmark {\n",
       "  x: 0.528844\n",
       "  y: 0.507408917\n",
       "  z: -0.791513383\n",
       "  visibility: 0.999942601\n",
       "}\n",
       "landmark {\n",
       "  x: 0.513014913\n",
       "  y: 0.511374593\n",
       "  z: -0.791813\n",
       "  visibility: 0.999931037\n",
       "}\n",
       "landmark {\n",
       "  x: 0.661555886\n",
       "  y: 0.527239919\n",
       "  z: -0.453322\n",
       "  visibility: 0.999927521\n",
       "}\n",
       "landmark {\n",
       "  x: 0.494069397\n",
       "  y: 0.550649762\n",
       "  z: -0.421676815\n",
       "  visibility: 0.999957\n",
       "}\n",
       "landmark {\n",
       "  x: 0.622580886\n",
       "  y: 0.630941272\n",
       "  z: -0.718244672\n",
       "  visibility: 0.999945223\n",
       "}\n",
       "landmark {\n",
       "  x: 0.548650861\n",
       "  y: 0.634876966\n",
       "  z: -0.708034098\n",
       "  visibility: 0.999958336\n",
       "}\n",
       "landmark {\n",
       "  x: 0.840399742\n",
       "  y: 0.918208718\n",
       "  z: -0.269017041\n",
       "  visibility: 0.998240173\n",
       "}\n",
       "landmark {\n",
       "  x: 0.371536016\n",
       "  y: 0.907081425\n",
       "  z: -0.34915942\n",
       "  visibility: 0.998319924\n",
       "}\n",
       "landmark {\n",
       "  x: 0.906945586\n",
       "  y: 1.32068121\n",
       "  z: -0.349260479\n",
       "  visibility: 0.225872546\n",
       "}\n",
       "landmark {\n",
       "  x: 0.257675827\n",
       "  y: 1.31965232\n",
       "  z: -0.457046807\n",
       "  visibility: 0.131790832\n",
       "}\n",
       "landmark {\n",
       "  x: 0.902082086\n",
       "  y: 1.6516062\n",
       "  z: -0.711835444\n",
       "  visibility: 0.515243292\n",
       "}\n",
       "landmark {\n",
       "  x: 0.245406479\n",
       "  y: 1.63479733\n",
       "  z: -1.0511657\n",
       "  visibility: 0.0955185369\n",
       "}\n",
       "landmark {\n",
       "  x: 0.933597088\n",
       "  y: 1.76208031\n",
       "  z: -0.821501613\n",
       "  visibility: 0.523206413\n",
       "}\n",
       "landmark {\n",
       "  x: 0.201915309\n",
       "  y: 1.74474466\n",
       "  z: -1.19658518\n",
       "  visibility: 0.140188307\n",
       "}\n",
       "landmark {\n",
       "  x: 0.886391759\n",
       "  y: 1.76871121\n",
       "  z: -0.88123\n",
       "  visibility: 0.539933562\n",
       "}\n",
       "landmark {\n",
       "  x: 0.254305661\n",
       "  y: 1.75568628\n",
       "  z: -1.27945507\n",
       "  visibility: 0.22141625\n",
       "}\n",
       "landmark {\n",
       "  x: 0.864611\n",
       "  y: 1.72261095\n",
       "  z: -0.759722829\n",
       "  visibility: 0.531606674\n",
       "}\n",
       "landmark {\n",
       "  x: 0.279464662\n",
       "  y: 1.70656\n",
       "  z: -1.1090821\n",
       "  visibility: 0.214162931\n",
       "}\n",
       "landmark {\n",
       "  x: 0.739665151\n",
       "  y: 1.70655489\n",
       "  z: -0.0645081624\n",
       "  visibility: 0.00180059695\n",
       "}\n",
       "landmark {\n",
       "  x: 0.433422893\n",
       "  y: 1.70369315\n",
       "  z: 0.0698337629\n",
       "  visibility: 0.00133890135\n",
       "}\n",
       "landmark {\n",
       "  x: 0.712197244\n",
       "  y: 2.35286975\n",
       "  z: -0.0474214405\n",
       "  visibility: 0.00267033209\n",
       "}\n",
       "landmark {\n",
       "  x: 0.424907684\n",
       "  y: 2.35877538\n",
       "  z: 0.10103716\n",
       "  visibility: 0.000467308244\n",
       "}\n",
       "landmark {\n",
       "  x: 0.693247139\n",
       "  y: 2.94120789\n",
       "  z: 0.566965759\n",
       "  visibility: 0.000158246941\n",
       "}\n",
       "landmark {\n",
       "  x: 0.419972718\n",
       "  y: 2.93327403\n",
       "  z: 0.510872602\n",
       "  visibility: 8.28440716e-006\n",
       "}\n",
       "landmark {\n",
       "  x: 0.699654341\n",
       "  y: 3.03918386\n",
       "  z: 0.593877733\n",
       "  visibility: 0.000156464244\n",
       "}\n",
       "landmark {\n",
       "  x: 0.417840183\n",
       "  y: 3.03450012\n",
       "  z: 0.532783031\n",
       "  visibility: 2.27378514e-005\n",
       "}\n",
       "landmark {\n",
       "  x: 0.640596807\n",
       "  y: 3.11991453\n",
       "  z: 0.0184845068\n",
       "  visibility: 0.000360402715\n",
       "}\n",
       "landmark {\n",
       "  x: 0.446152538\n",
       "  y: 3.11093426\n",
       "  z: -0.0898122862\n",
       "  visibility: 0.000114425922\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafeb67c-98b8-4e02-a49d-96c3d7ce7699",
   "metadata": {},
   "source": [
    "## 6. Load saved video and make csv file through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb5f50-5a4c-4450-b297-396feb46b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('ml.avi')\n",
    "# Initiate holistic model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.2) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolour Feed\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = pose.process(frame)\n",
    "\n",
    "        # Recolour frame back to BGR for rendering\n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(117,66,117), thickness=2, circle_radius=2))\n",
    "\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == ord('r'):\n",
    "            export_landmarks(results, \"right\")\n",
    "        if k == ord('l'):\n",
    "            export_landmarks(results, \"left\")\n",
    "        if k == ord('m'):\n",
    "            export_landmarks(results, \"mid\")\n",
    "        \n",
    "        cv2.imshow('Raw webcam feed',frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c81fc2-9a93-4d0f-870c-83589c33d35b",
   "metadata": {},
   "source": [
    "## 7. Train Coustom Model (wide narrow neutral) using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "375dc191-68a3-4793-af71-382bc651d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa91cf37-c15c-4edb-9fef-1a8b542e7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"landmarks.csv\") # if you didn't changed it in video_capture.ipynb, then it is \"landmarks.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329cf25-27bc-4457-b7d8-911dda27b217",
   "metadata": {},
   "source": [
    "*7.1 Split data into x and y.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b38822-650a-4356-a2ad-27744badb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0abbbd-e96d-4307-9725-0c4e34395b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe5aaf3-b215-40be-9c43-21d0a49fc1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6daf77bf-f450-4e48-935f-fe566d2a16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(x_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44bc3668-630f-44d0-ace2-56dcd88f3694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0ce9a4-11df-4416-83fc-3571b28de085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['right', 'right', 'right', 'left', 'right', 'left', 'left',\n",
       "       'right', 'left', 'left', 'right', 'right', 'left', 'right',\n",
       "       'right', 'left', 'right', 'left', 'right', 'right', 'right',\n",
       "       'left', 'right', 'left', 'left', 'left', 'left', 'left', 'left',\n",
       "       'right', 'left', 'right', 'left', 'left', 'left', 'left', 'left',\n",
       "       'left', 'left', 'right', 'right', 'left', 'right', 'left', 'right',\n",
       "       'left', 'right', 'left', 'left', 'right', 'right', 'left', 'right',\n",
       "       'right', 'right'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['gb'].predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065dba3-b36d-48b1-8809-09c4e7d2880f",
   "metadata": {},
   "source": [
    "## 8. Evaluate and serialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb28eab-becd-4ff7-9f2e-f33b200734f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17899a9d-2884-4127-b753-777c7a67bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf 1.0 1.0 1.0\n",
      "gb 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(x_test)\n",
    "    print(algo, accuracy_score(y_test.values, yhat),\n",
    "         precision_score(y_test.values, yhat, average='weighted'),\n",
    "         recall_score(y_test.values, yhat, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8ab49-1a51-46a8-a3d5-623e7de49c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wide_narrow_neutral.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760fcda-7f43-4005-91e8-e1b0f71fd261",
   "metadata": {},
   "source": [
    "*8.1 Make detections with model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6998679-4cee-4d68-a0d4-94ff305daa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "with open(\"wide_narrow_neutral.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061187c-fbe6-45a2-8ed5-18ca15c7a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "current_stage = ''\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # recolour feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detections\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolour image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245, 117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(117,66,117), thickness=2, circle_radius=2)\n",
    "                                                       )\n",
    "        try:\n",
    "            row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "            X = pd.DataFrame([row], columns=landmarks[1:])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "\n",
    "            if body_language_class == 'down' and body_language_prob[body_language_prob.argmax()] >= 0.9:\n",
    "                current_stage = 'down'\n",
    "            elif current_stage == 'down' and body_language_class == 'up' and body_language_prob[body_language_prob.argmax()] >= 0.9:\n",
    "                current_stage = 'up'\n",
    "                counter += 1\n",
    "                print(current_stage)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Executing except condition\")\n",
    "\n",
    "        # Get status box\n",
    "        cv2.rectangle(image, (0,0), (250,60), (245, 117, 16), -1)\n",
    "    \n",
    "        # Display class\n",
    "        cv2.putText(image, 'CLASS',\n",
    "                       (95, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, body_language_class.split(' ')[0],\n",
    "                        (90, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "        # Display probability\n",
    "        cv2.putText(image, 'PROB',\n",
    "                        (15, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)], 2)),\n",
    "                        (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"detection frame\", image)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
